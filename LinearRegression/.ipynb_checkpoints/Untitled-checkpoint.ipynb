{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scio\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scio.loadmat('HW1_Data/dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X_trn']\n",
    "Y = data['Y_trn']\n",
    "X_test = data['X_tst']\n",
    "Y_test = data['Y_tst']\n",
    "\n",
    "degree = 3\n",
    "\n",
    "X = transform(X, degree)\n",
    "X = np.matrix(X)\n",
    "Y = np.matrix(Y)\n",
    "theta0 = np.matrix(np.zeros(degree+1))\n",
    "alpha = 0.009\n",
    "iters = 1000\n",
    "batchSize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y, y_pred):\n",
    "    return np.mean((y - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    inner = np.power(((X * theta.T) - y), 2)\n",
    "    return np.sum(inner) / (2 * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closedFormEquation(X, y):\n",
    "    return (X.T * X).I * (X.T * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, degree):\n",
    "    Z = A = X\n",
    "    for i in range(degree-1):\n",
    "        Z = Z * A\n",
    "        X = np.insert(X, [i+1], Z, axis=1)\n",
    "    return np.insert(X, 0, 1, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchGradientDescent(X, y, theta, alpha, iters):\n",
    "    temp = np.matrix(np.zeros(theta.shape))\n",
    "    parameters = theta.ravel().shape[1]\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        error = (X * theta.T) - y\n",
    "        \n",
    "        for j in range(parameters):\n",
    "            term = np.multiply(error, X[:,j])\n",
    "            temp[0,j] = theta[0,j] - ((alpha / len(X)) * np.sum(term))\n",
    "            \n",
    "        theta = temp\n",
    "        cost[i] = computeCost(X, y, theta)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"Loss iter\",i,\": \",cost[i])\n",
    "        \n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochasticGradientDescent(X, y, theta, alpha, iters, minibatch_size):\n",
    "    temp = np.matrix(np.zeros(theta.shape))\n",
    "    parameters = theta.ravel().shape[1]\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        # idx = np.random.choice(10, size=5, replace = False)   # generates random samples without replacement (all unique)\n",
    "        for batch in range(0, X.shape[0], minibatch_size):\n",
    "            # Get pair of (X, y) of the current minibatch/chunk\n",
    "            X_mini = X[batch:batch + minibatch_size]\n",
    "            y_mini = y[batch:batch + minibatch_size]\n",
    "            \n",
    "            error = (X_mini * theta.T) - y_mini\n",
    "            \n",
    "            for j in range(parameters):\n",
    "                term = np.multiply(error, X_mini[:,j])\n",
    "                temp[0,j] = theta[0,j] - ((alpha / len(X_mini)) * np.sum(term))\n",
    "\n",
    "            theta = temp\n",
    "            \n",
    "        cost[i] = computeCost(X, y, theta)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"Loss iter\",i,\": \",cost[i])\n",
    "        \n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.00815033   0.20418927   1.47413164   0.47320168]]\n"
     ]
    }
   ],
   "source": [
    "closed_form_output = closedFormEquation(X, Y)\n",
    "print(closed_form_output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss iter 0 :  184.311105069\n",
      "Loss iter 50 :  22.5713489268\n",
      "Loss iter 100 :  21.0831055852\n",
      "Loss iter 150 :  20.2582921493\n",
      "Loss iter 200 :  19.4724231181\n",
      "Loss iter 250 :  18.7211730224\n",
      "Loss iter 300 :  18.0029427796\n",
      "Loss iter 350 :  17.3162223027\n",
      "Loss iter 400 :  16.6595751106\n",
      "Loss iter 450 :  16.0316343644\n",
      "Loss iter 500 :  15.4310991847\n",
      "Loss iter 550 :  14.8567311834\n",
      "Loss iter 600 :  14.3073511993\n",
      "Loss iter 650 :  13.781836221\n",
      "Loss iter 700 :  13.2791164885\n",
      "Loss iter 750 :  12.7981727594\n",
      "Loss iter 800 :  12.3380337302\n",
      "Loss iter 850 :  11.8977736035\n",
      "Loss iter 900 :  11.4765097913\n",
      "Loss iter 950 :  11.0734007456\n",
      "[[ 3.68226304  0.38960716  2.13209267  0.45673429]]\n"
     ]
    }
   ],
   "source": [
    "batchgradient_output = batchGradientDescent(X, Y, theta0, alpha, iters)\n",
    "print(batchgradient_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss iter 0 :  49.5483230612\n",
      "Loss iter 50 :  10.1098247018\n",
      "Loss iter 100 :  10.0209537527\n",
      "Loss iter 150 :  10.0250394525\n",
      "Loss iter 200 :  10.0253489793\n",
      "Loss iter 250 :  10.0253672523\n",
      "Loss iter 300 :  10.0253682839\n",
      "Loss iter 350 :  10.0253683415\n",
      "Loss iter 400 :  10.0253683447\n",
      "Loss iter 450 :  10.0253683449\n",
      "Loss iter 500 :  10.0253683449\n",
      "Loss iter 550 :  10.0253683449\n",
      "Loss iter 600 :  10.0253683449\n",
      "Loss iter 650 :  10.0253683449\n",
      "Loss iter 700 :  10.0253683449\n",
      "Loss iter 750 :  10.0253683449\n",
      "Loss iter 800 :  10.0253683449\n",
      "Loss iter 850 :  10.0253683449\n",
      "Loss iter 900 :  10.0253683449\n",
      "Loss iter 950 :  10.0253683449\n",
      "[[ 10.84337345  -0.79052534   1.41330197   0.40207248]]\n"
     ]
    }
   ],
   "source": [
    "stochasticgradient_output = stochasticGradientDescent(X, Y, theta0, alpha, iters, batchSize)\n",
    "print(stochasticgradient_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98393157851\n"
     ]
    }
   ],
   "source": [
    "print(computeCost(X, Y, closed_form_output.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.6951940053\n"
     ]
    }
   ],
   "source": [
    "print(computeCost(X, Y, batchgradient_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0253683449\n"
     ]
    }
   ],
   "source": [
    "print(computeCost(X, Y, stochasticgradient_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
